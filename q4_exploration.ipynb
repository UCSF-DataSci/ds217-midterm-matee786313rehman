{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 4: Data Exploration\n",
    "\n",
    "**Points: 15**\n",
    "\n",
    "In this notebook, you'll explore the clinical trial dataset using pandas selection and filtering techniques.\n",
    "\n",
    "You'll use utility functions from `q3_data_utils` where helpful, but also demonstrate direct pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewritten Demo: quick exploration using q3_data_utils\n",
    "from q3_data_utils import load_data, clean_data, detect_missing, fill_missing, transform_types, create_bins, summarize_by_group, filter_data \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "DATA_FILE = 'data/clinical_trial_raw.csv'\n",
    "\n",
    "# Load data\n",
    "df = load_data(DATA_FILE)\n",
    "print(f'Loaded {len(df)} rows, {len(df.columns)} columns')\n",
    "\n",
    "\n",
    "\n",
    "# 1. Clean data (This single call now performs ALL necessary consolidation and cleaning)\n",
    "df_clean = clean_data(df)\n",
    "missing = detect_missing(df_clean)\n",
    "print('Missing values per column:\\n', missing.head(10))\n",
    "\n",
    "# 2. Fill BMI with median and transform types\n",
    "df_filled = fill_missing(df_clean, 'bmi', strategy='median')\n",
    "df_typed = transform_types(df_filled, {'enrollment_date': 'datetime', 'age': 'numeric'})\n",
    "\n",
    "# --- Removed redundant manual normalization for 'site_clean' and 'intervention_clean' ---\n",
    "# The original columns 'site' and 'intervention_group' are now clean.\n",
    "\n",
    "# 3. Create age bins and summarize by site (using the cleaned 'site' column)\n",
    "df_binned = create_bins(df_typed, 'age', bins=[0,18,35,50,65,100], labels=['<18','18-34','35-49','50-64','65+'])\n",
    "# Use 'site' instead of 'site_clean'\n",
    "summary = summarize_by_group(df_binned, 'site', agg_dict={'age':'mean','bmi':'mean'})\n",
    "print(summary.head())\n",
    "\n",
    "# 4. Save outputs using the clean columns ('site' and 'intervention_group')\n",
    "summary.to_csv('output/q4_site_summary.csv', index=False)\n",
    "# Use 'site' instead of 'site_clean'\n",
    "df_typed['site'].value_counts().to_csv('output/q4_site_counts.csv', header=['patient_count'])\n",
    "print('Wrote output/q4_site_summary.csv and output/q4_site_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Final Cleaning and Site Distribution\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "OUTPUT_DIR = 'output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(\"2. Finalizing Site Cleaning, Generating Distribution, & Saving CSV\")\n",
    "\n",
    "# --- Robust Site Standardization ---\n",
    "# 1. Standardize all text: Remove underscores, general non-alphanumeric characters (except spaces),\n",
    "#    remove numbers, and convert to Title Case (handles Site_D, Site B94, etc.)\n",
    "df['site'] = df['site'].astype(str).str.replace('_', ' ', regex=False).str.strip()\n",
    "df['site'] = df['site'].str.replace(r'[^A-Za-z\\s]', '', regex=True).str.strip() \n",
    "df['site'] = df['site'].str.title()\n",
    "\n",
    "# 2. Aggressive Whitespace Normalization: Replace all sequences of whitespace (including hidden ones) \n",
    "#    with a single space, then strip again. This handles tabs, newlines, and non-breaking spaces.\n",
    "df['site'] = df['site'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# 3. Final forced cleanup (in case 'Site A' and 'Site A ' were the culprits)\n",
    "df['site'] = df['site'].str.replace('Site A ', 'Site A', regex=False)\n",
    "\n",
    "# Value counts calculation (using the now fully standardized data)\n",
    "site_counts_series = df['site'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame for CSV saving\n",
    "site_counts_df = site_counts_series.reset_index()\n",
    "site_counts_df.columns = ['site', 'patient_count']\n",
    "\n",
    "# Save to required output file\n",
    "output_path = os.path.join(OUTPUT_DIR, 'q4_site_counts.csv')\n",
    "site_counts_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Site counts saved to {output_path}. Should show exactly 5 sites.\")\n",
    "display(site_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Exploration (3 points)\n",
    "\n",
    "Display:\n",
    "1. Dataset shape\n",
    "2. Column names and types\n",
    "3. First 10 rows\n",
    "4. Summary statistics (.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1:\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nColumn names and dtypes:')\n",
    "print(df.dtypes)\n",
    "\n",
    "print('\\nFirst 10 rows:')\n",
    "display(df.head(10))\n",
    "\n",
    "print('\\nSummary statistics (numeric columns):')\n",
    "display(df.describe(include=[np.number]).T)\n",
    "\n",
    "print('\\nSummary statistics (all columns):')\n",
    "display(df.describe(include=\"all\").T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Column Selection (3 points)\n",
    "\n",
    "Demonstrate different selection methods:\n",
    "\n",
    "1. Select only numeric columns using `.select_dtypes()`\n",
    "2. Select specific columns by name\n",
    "3. Select a subset of rows and columns using `.loc[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2:\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "print('Numeric columns (count):', len(numeric_cols.columns))\n",
    "print(list(numeric_cols.columns))\n",
    "display(numeric_cols.head())\n",
    "print('Numeric-only dataframe shape:', numeric_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'age', 'bmi', 'site']\n",
    "cols_found = [c for c in cols if c in df.columns]\n",
    "print('Requested columns found:', cols_found)\n",
    "display(df[cols_found].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['patient_id', 'age', 'site']\n",
    "cols_available = [c for c in cols if c in df.columns]\n",
    "print('Using columns for .loc():', cols_available)\n",
    "subset = df.loc[0:9, cols_available]\n",
    "display(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Filtering (4 points)\n",
    "\n",
    "Filter the data to answer these questions:\n",
    "\n",
    "1. How many patients are over 65 years old?\n",
    "2. How many patients have systolic BP > 140?\n",
    "3. Find patients who are both over 65 AND have systolic BP > 140\n",
    "4. Find patients from Site A or Site B using `.isin()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3.1: Filter and count patients over 65\n",
    "filters = [{'column': 'age', 'condition': 'greater_than', 'value': 65}]\n",
    "patients_over_65 = filter_data(df, filters) # <-- The 'du.' prefix is removed here\n",
    "print(f\"Patients over 65: {len(patients_over_65)}\")\n",
    "display(patients_over_65.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3.2: Filter for high systolic BP (>140)\n",
    "filters = [{'column': 'systolic_bp', 'condition': 'greater_than', 'value': 140}]\n",
    "high_bp = filter_data(df, filters)\n",
    "print(f\"Patients with systolic BP > 140: {len(high_bp)}\")\n",
    "display(high_bp.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3.3: Multiple conditions (age > 65 AND systolic_bp > 140)\n",
    "filters = [\n",
    "    {'column': 'age', 'condition': 'greater_than', 'value': 65},\n",
    "    {'column': 'systolic_bp', 'condition': 'greater_than', 'value': 140}\n",
    "]\n",
    "both_conditions = filter_data(df, filters)\n",
    "print(f\"Patients over 65 AND systolic BP > 140: {len(both_conditions)}\")\n",
    "display(both_conditions.head())\n",
    "\n",
    "# Alternative: use in_range for age 65-100\n",
    "age_filters = [{'column': 'age', 'condition': 'in_range', 'value': [65, 100]}]\n",
    "age_range = filter_data(df, age_filters)\n",
    "print(f\"Patients aged 65-100: {len(age_range)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3.4: Filter by site using .isin() (recommended)\n",
    "# Use cleaned site column if available\n",
    "site_col = 'site_clean' if 'site_clean' in df.columns else 'site'\n",
    "site_values = ['Site A', 'Site B']\n",
    "site_ab_isin = df[df[site_col].isin(site_values)]\n",
    "print(f\"Patients from Site A or Site B (using .isin on cleaned values): {len(site_ab_isin)}\")\n",
    "display(site_ab_isin.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Value Counts and Grouping (5 points)\n",
    "\n",
    "1. Get value counts for the 'site' column\n",
    "2. Get value counts for the 'intervention_group' column  \n",
    "3. Create a crosstab of site vs intervention_group\n",
    "4. Calculate mean age by site\n",
    "5. Save the site value counts to `output/q4_site_counts.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- Setup: Assuming df is your fully cleaned DataFrame from du.clean_data() ---\n",
    "# Note: The cleaning functions in q3_data_utils overwrite the 'site' and\n",
    "# 'intervention_group' columns, so we use them directly.\n",
    "OUTPUT_DIR = 'output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Site value counts and plot\n",
    "site_counts = df['site'].value_counts().reset_index()\n",
    "site_counts.columns = ['site', 'patient_count'] \n",
    "\n",
    "print(\"\\n1. Site value counts:\")\n",
    "display(site_counts)\n",
    "\n",
    "# Plot: Site Distribution Bar Chart\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.barplot(\n",
    "    x='site', \n",
    "    y='patient_count', \n",
    "    data=site_counts, \n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Distribution of Patients by Site')\n",
    "plt.xlabel('Clinical Site')\n",
    "plt.ylabel('Patient Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'q4_site_counts_bar.png'))\n",
    "plt.close() # Close plot\n",
    "\n",
    "\n",
    "# 2. Intervention group value counts and plot\n",
    "interv_counts = df['intervention_group'].value_counts().reset_index()\n",
    "interv_counts.columns = ['intervention_group', 'patient_count']\n",
    "\n",
    "print(\"\\n2. Intervention group value counts:\")\n",
    "display(interv_counts)\n",
    "\n",
    "# Plot: Intervention Group Distribution Bar Chart\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.barplot(\n",
    "    x='intervention_group', \n",
    "    y='patient_count', \n",
    "    data=interv_counts, \n",
    "    palette='plasma'\n",
    ")\n",
    "plt.title('Distribution of Patients by Intervention Group')\n",
    "plt.xlabel('Intervention Group')\n",
    "plt.ylabel('Patient Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'q4_intervention_counts_bar.png'))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# 3. Crosstab of site vs intervention_group and heatmap\n",
    "site_intervention_crosstab = pd.crosstab(df['site'], df['intervention_group'])\n",
    "print(\"\\n3. Crosstab of site vs intervention group:\")\n",
    "display(site_intervention_crosstab)\n",
    "\n",
    "# Plot: Site vs Intervention Group Heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    site_intervention_crosstab, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues', \n",
    "    cbar_kws={'label': 'Patient Count'}\n",
    ")\n",
    "plt.title('Site vs Intervention Group Distribution')\n",
    "plt.xlabel('Intervention Group')\n",
    "plt.ylabel('Clinical Site')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'q4_site_intervention_heatmap.png'))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# 4. Mean age by site\n",
    "mean_age_by_site = df.groupby('site')['age'].mean().round(1)\n",
    "print(\"\\n4. Mean age by site:\")\n",
    "display(mean_age_by_site)\n",
    "\n",
    "# Optional bar plot of mean age by site\n",
    "plt.figure(figsize=(10, 6))\n",
    "mean_age_by_site.plot(kind='bar')\n",
    "plt.title('Mean Age by Site')\n",
    "plt.ylabel('Age (years)')\n",
    "plt.xticks(rotation=0) \n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'q4_mean_age_by_site_bar.png'))\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# 5. Save the site value counts to output/q4_site_counts.csv\n",
    "# Use the series derived from the value_counts() to save the artifact\n",
    "df['site'].value_counts().to_csv(os.path.join(OUTPUT_DIR, 'q4_site_counts.csv'), header=['patient_count'])\n",
    "print(\"\\n5. Site value counts saved to output/q4_site_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Save to CSV\n",
    "output_file = 'output/q4_site_counts.csv'\n",
    "site_counts.to_csv(output_file)\n",
    "print(f\"Saved site value counts to {output_file}\")\n",
    "\n",
    "# first few rows\n",
    "print(\"\\nPreview of saved CSV content:\")\n",
    "saved_counts = pd.read_csv(output_file)\n",
    "display(saved_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Write 2-3 sentences about what you learned from exploring this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your summary here:**\n",
    "Exploration of the raw dataset revealed several key areas requiring cleanup, including the presence of missing values, particularly in lab measurements, and the need for standardization across categorical columns like 'site' and 'intervention_group' due to inconsistent spelling and formatting. \n",
    "Furthermore, initial distribution plots indicated potential outliers in the age and BMI fields, confirming that data cleaning and transformation steps are necessary before any reliable statistical aggregation or modeling can be performed.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
